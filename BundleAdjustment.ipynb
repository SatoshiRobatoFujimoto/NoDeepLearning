{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer.utils import type_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import function\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import reporter\n",
    "from chainer.dataset import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rot import rotation3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PreprocessedDataset(chainer.dataset.DatasetMixin):\n",
    "    def __init__(self, nb_data):\n",
    "        self.point3d = np.random.rand(nb_data, 3).astype(np.float32)\n",
    "        self.point3d[:, 2] += 2.0\n",
    "        self.matA = np.array([[600, 0, 300], [0, 600, 300], [0, 0, 1]], dtype=np.float32)\n",
    "        self.rvec = np.random.rand(3).astype(np.float32) / 10\n",
    "        self.tvec = np.random.rand(3).astype(np.float32)\n",
    "\n",
    "        p1 = np.tensordot(self.matA, self.point3d, ((1,), (1,))).T\n",
    "        self.p1 = p1[:,:2] / p1[:,2:]\n",
    "        self.p1 += 5 * np.random.rand(nb_data, 2).astype(np.float32)\n",
    "\n",
    "        rmat = self.rodrigues(self.rvec)\n",
    "        rp = np.tensordot(rmat, self.point3d, ((1,), (1,))).T\n",
    "        rpt = rp + np.broadcast_to(self.tvec, rp.shape)\n",
    "        p2 = np.tensordot(self.matA, rpt, ((1,), (1,))).T\n",
    "        self.p2 = p2[:,:2] / p2[:,2:]\n",
    "        self.p2 += 5 * np.random.rand(nb_data, 2).astype(np.float32)\n",
    "        \n",
    "    def rodrigues(self, r):\n",
    "            def S(n):\n",
    "                Sn = np.array([[0,-n[2],n[1]],[n[2],0,-n[0]],[-n[1],n[0],0]])\n",
    "                return Sn\n",
    "\n",
    "            theta = np.linalg.norm(r)\n",
    "\n",
    "            if theta > 1e-16:\n",
    "                n = r / theta\n",
    "                Sn = S(n)\n",
    "                R = np.eye(3) + \\\n",
    "                    np.sin(theta) * Sn + \\\n",
    "                    (1 - np.cos(theta)) * np.dot(Sn, Sn)\n",
    "            else:\n",
    "                Sr = S(r)\n",
    "                theta2 = theta**2\n",
    "                R = np.eye(3) + \\\n",
    "                    (1- theta2/6.) * Sr + \\\n",
    "                    (.5 - theta2/24.) * np.dot(Sr, Sr)\n",
    "\n",
    "            return R.astype(r.dtype)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.p1)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        return self.p1[i], self.p2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = PreprocessedDataset(nb_data = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p0, p1 = convert.concat_examples(data[:], -1)\n",
    "E, mask = cv2.findEssentialMat(p0, p1, data.matA, method=cv2.RANSAC, prob=0.999, threshold=3.0)\n",
    "_, rmat, tvec, _ = cv2.recoverPose(E, p0, p1)\n",
    "rvec, _ = cv2.Rodrigues(rmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl = np.dot(data.matA, np.eye(3, 4, dtype=np.float32))\n",
    "pr = np.dot(data.matA, np.concatenate((rmat, tvec.reshape(3,1)), axis=1))\n",
    "point4d = cv2.triangulatePoints(pl, pr, p0.T, p1.T).T\n",
    "point3d = (point4d[:] / point4d[:,3:])[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(chainer.Chain):\n",
    "    def __init__(self, matA, nb_data, rvec=None, tvec=None, points=None):\n",
    "        super(Net, self).__init__()\n",
    "        self.matA = matA\n",
    "        \n",
    "        embd = None\n",
    "        if rvec is not None and tvec is not None:\n",
    "            embd = np.stack((rvec, tvec), axis=0)\n",
    "            \n",
    "        pts = None\n",
    "        if points is not None:\n",
    "            pts = points.reshape(-1)\n",
    "            \n",
    "        with self.init_scope():\n",
    "            self.embd = L.EmbedID(2, 3, initialW=embd)\n",
    "            self.points = L.EmbedID(1, 3 * nb_data, pts)\n",
    "\n",
    "    def proj(self, x):\n",
    "        xy, z = F.split_axis(x, (2,), axis=1)\n",
    "        r = xy / F.broadcast_to(z, xy.shape)\n",
    "        return r\n",
    "\n",
    "    def __call__(self):\n",
    "        xp = self.xp            \n",
    "        matA = xp.asarray(self.matA)\n",
    "        \n",
    "        pts = self.points(xp.array([0], dtype=np.int32))\n",
    "        pts = F.reshape(pts, (-1, 3))\n",
    "            \n",
    "        p0 = F.matmul(pts, matA, transa=False, transb=True)\n",
    "        p0 = self.proj(p0)\n",
    "        \n",
    "        r = self.embd(xp.array([0], dtype=np.int32))\n",
    "        r = F.reshape(r, (3,))\n",
    "        \n",
    "        t = self.embd(xp.array([1], dtype=np.int32))\n",
    "        t = F.broadcast_to(t, pts.shape)\n",
    "        \n",
    "        rxt = rotation3d(pts, r) + t\n",
    "        p1 = F.matmul(rxt, matA, transa=False, transb=True)\n",
    "        p1 = self.proj(p1)\n",
    "\n",
    "        return p0, p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net(data.matA, nb_data = len(data), rvec=rvec[:,0], tvec=tvec[:,0], points=point3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class loss_function(chainer.link.Chain):\n",
    "    def __init__(self, predictor):\n",
    "        super(loss_function, self).__init__(predictor=predictor)\n",
    "\n",
    "    def __call__(self, p0, p1):\n",
    "        q0, q1 = self.predictor()\n",
    "        self.loss = F.mean_squared_error(p0, q0) + F.mean_squared_error(p1, q1)\n",
    "        reporter.report({'loss': self.loss}, self)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = loss_function(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable(5.782209396362305)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(*convert.concat_examples(data[:], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, train mean loss: 2.7821598052978516\n",
      "epoch: 200, train mean loss: 2.682826042175293\n",
      "epoch: 300, train mean loss: 2.603457450866699\n",
      "epoch: 400, train mean loss: 2.535459518432617\n",
      "epoch: 500, train mean loss: 2.4778831005096436\n",
      "epoch: 600, train mean loss: 2.429232597351074\n",
      "epoch: 700, train mean loss: 2.3879027366638184\n",
      "epoch: 800, train mean loss: 2.3529210090637207\n",
      "epoch: 900, train mean loss: 2.3226137161254883\n",
      "epoch: 1000, train mean loss: 2.295989990234375\n"
     ]
    }
   ],
   "source": [
    "data_iter = chainer.iterators.SerialIterator(data, len(data), shuffle=False)\n",
    "data_count = len(data)\n",
    "\n",
    "sum_loss = 0\n",
    "\n",
    "while data_iter.epoch < 1000:\n",
    "    batch = data_iter.next()\n",
    "    x_array, y_array = convert.concat_examples(batch, -1)\n",
    "    x = chainer.Variable(x_array)\n",
    "    y = chainer.Variable(y_array)\n",
    "    optimizer.update(model, x, y)\n",
    "    sum_loss += float(model.loss.data) * len(y.data)\n",
    "\n",
    "    if data_iter.is_new_epoch:\n",
    "        if data_iter.epoch % 100 == 0:\n",
    "            print('epoch: {}, train mean loss: {}'.format(data_iter.epoch, sum_loss / data_count))\n",
    "        sum_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
